{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Flatten,Dropout,Dense,BatchNormalization,Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loding Train dataset :\n",
      "100.00 %\n",
      "Loding Test dataset :\n",
      "100.00 %\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "path_train_low='../dataSets/ref/our485/low/'\n",
    "path_train_high='../dataSets/ref/our485/high/'\n",
    "path_test_low='../dataSets/ref/eval15/low/'\n",
    "path_test_high='../dataSets/ref/eval15/high/'\n",
    "\n",
    "print('\\nLoding Train dataset :')\n",
    "i=0;\n",
    "for img in os.listdir(path_train_low):\n",
    "    img_low_path=os.path.join(path_train_low, img)\n",
    "    img_high_path=os.path.join(path_train_high, img)\n",
    "    \n",
    "    img_low=load_img(img_low_path, target_size=(50,50))\n",
    "    img_low=img_to_array(img_low)/255.\n",
    "    \n",
    "    i=i+1\n",
    "    print(\"{:.2f}\".format(i/4.85)+' %',end='\\r')\n",
    "    \n",
    "    img_high=load_img(img_high_path, target_size=(50,50))\n",
    "    img_high=img_to_array(img_high)/255.\n",
    "    \n",
    "    x_train.append(img_low)\n",
    "    y_train.append(img_high)\n",
    "    \n",
    "print('\\nLoding Test dataset :')\n",
    "i=0;\n",
    "for img in os.listdir(path_test_low):\n",
    "    img_low_path=os.path.join(path_test_low, img)\n",
    "    img_high_path=os.path.join(path_test_high, img)\n",
    "    \n",
    "    img_low=load_img(img_low_path, target_size=(50,50))\n",
    "    img_low=img_to_array(img_low)/255.\n",
    "    \n",
    "    i=i+1\n",
    "    print(\"{:.2f}\".format(i/0.15)+' %',end='\\r')\n",
    "    \n",
    "    img_high=load_img(img_high_path, target_size=(50,50))\n",
    "    img_high=img_to_array(img_high)/255.\n",
    "    \n",
    "    x_test.append(img_low)\n",
    "    y_test.append(img_high)\n",
    "\n",
    "x_train=np.array(x_train, dtype=\"float32\")\n",
    "y_train=np.array(y_train, dtype=\"float32\")\n",
    "\n",
    "x_test=np.array(x_test, dtype=\"float32\")\n",
    "y_test=np.array(y_test, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d (UpSampling2D) (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 150, 150, 100)     7600      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 50)      45050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 125000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2500)              312502500 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7500)              18757500  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 50, 50, 3)         0         \n",
      "=================================================================\n",
      "Total params: 331,312,650\n",
      "Trainable params: 331,312,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(UpSampling2D((3,3),input_shape=(50,50,3)))\n",
    "model.add(Conv2D(100,(5,5),padding='same',activation='relu'))\n",
    "model.add(Conv2D(50,(3,3),padding='same',activation='elu'))\n",
    "model.add(MaxPooling2D((3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50*50,activation='elu'))\n",
    "model.add(Dense(3*50*50,activation='sigmoid'))\n",
    "model.add(Reshape((50,50,3)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.3836 \n",
      "Epoch 00001: val_loss improved from inf to 0.04919, saving model to models/ref\\ref_cnn_mod.h5\n",
      "16/16 [==============================] - 570s 36s/step - loss: 0.0484 - accuracy: 0.3836 - val_loss: 0.0492 - val_accuracy: 0.3875\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.4227 \n",
      "Epoch 00002: val_loss improved from 0.04919 to 0.03874, saving model to models/ref\\ref_cnn_mod.h5\n",
      "16/16 [==============================] - 537s 34s/step - loss: 0.0388 - accuracy: 0.4227 - val_loss: 0.0387 - val_accuracy: 0.3811\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.4509 \n",
      "Epoch 00003: val_loss improved from 0.03874 to 0.03658, saving model to models/ref\\ref_cnn_mod.h5\n",
      "16/16 [==============================] - 526s 33s/step - loss: 0.0324 - accuracy: 0.4509 - val_loss: 0.0366 - val_accuracy: 0.4267\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.5157 \n",
      "Epoch 00004: val_loss improved from 0.03658 to 0.03103, saving model to models/ref\\ref_cnn_mod.h5\n",
      "16/16 [==============================] - 565s 35s/step - loss: 0.0278 - accuracy: 0.5157 - val_loss: 0.0310 - val_accuracy: 0.5078\n",
      "Epoch 5/100\n",
      " 8/16 [==============>...............] - ETA: 3:46 - loss: 0.0243 - accuracy: 0.5425"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint=ModelCheckpoint('models/ref/ref_cnn_mod.h5',\n",
    "                            monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True,\n",
    "                            verbose=1\n",
    "                          )\n",
    "earlystop=EarlyStopping(monitor='val_loss',\n",
    "                        patience=6,\n",
    "                        min_delta=0,\n",
    "                        restore_best_weights=True,\n",
    "                        verbose=1\n",
    "                       )\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss',\n",
    "                            factor=0.2,\n",
    "                            patience=6,\n",
    "                            min_delta=0.0001,\n",
    "                            verbose=1\n",
    "                           )\n",
    "callbacks=[checkpoint,earlystop,reduce_lr]\n",
    "\n",
    "model.compile(loss=keras.losses.MeanSquaredError(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history=model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure();\n",
    "\n",
    "def check_result(n):\n",
    "    fig.add_subplot(1,2,1).imshow(y_test[n])\n",
    "    fig.add_subplot(1,2,2).imshow(model.predict(x_test)[n])\n",
    "\n",
    "check_result(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Conv2D(3,(1,1),padding='same',activation='elu')(x_test)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
